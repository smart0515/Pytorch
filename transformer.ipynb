{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-07T06:07:39.816104Z",
     "start_time": "2023-02-07T06:07:36.128357Z"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer   # 트랜스포머에 특화된 모듈\n",
    "import torchtext   # torchtext.datasets에서 사용 가능한 데이터셋 다운로드를 위한 모듈\n",
    "from torchtext.data.utils import get_tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 트랜스포머 모델 아키텍처"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <img src=\"https://wikidocs.net/images/page/159310/img_original_paper-726x1030.png\" width=\"400\" height=\"200\" align=\"left\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**임베딩 계층**<br>\n",
    "이 계층은 임베딩, 즉 시퀀스의 각 입력 단어를 숫자 벡터로 변환하는 전형적인 작업을 수행한다.<br>\n",
    "- torch.nn.Embedding 모듈을 사용한다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**위치 인코더(PosEnc)** <br>\n",
    "트랜스포머 아키텍처에는 순환 계층이 없지만 시퀀스 작업에서 순환 네트워크보다 성능이 뛰어나다.<br>\n",
    "어떻게 가능할까? <br>\n",
    "- 위치 인코딩이라는 트릭으로 모델이 데이터의 순서에 대해 감을 잡을 수 있다.\n",
    "1. 특정 순차 패턴을 따르는 벡터가 입력 단어 임베딩에 추가된다. <br>\n",
    "2. 이러한 벡터는 모델에서 첫 번째 단어 뒤에 두 번째 단어가 따라 나오는 것을 이해할 수 있게 하는 방식으로 생성된다.<br> \n",
    "3. 벡터는 후속 단어 사이의 규칙적인 주기성과 거리를 나타내기 위해 각각 사인,코사인 곡선 함수를 사용해 생성된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**멀티-헤드 어텐션**\n",
    "1. 시퀀스의 각 단어 임베딩은 셀프-어텐션 계층을 통과해 단어 임베딩과 똑같은 길이의 개별 출력을 만들어낸다.\n",
    "2. scaled-dot attention 과정을 거쳐서 attention value 값을 구한다.\n",
    "3. concat 한다.\n",
    "- 이렇게 셀프-어텐션 헤드를 여러 개 두면 여러 개의 헤드가 시퀀스 단어의 다양한 관점에 집중하도록 도와준다.<br>\n",
    "이는 합성곱 신경망에서 여러 개의 특징 맵이 다양한 패턴을 학습하는 방법과 유사하다.\n",
    "<br><br>\n",
    "- 디코더 유닛의 마스킹된 멀티-헤드 어텐션 계층이 추가 됐다는 점을 제외하면 이전과 동일한 방식으로 작동한다.<br>\n",
    "디코더는 출력 시퀀스를 입력으로 한 번에 받기 때문에, 현재 시점의 단어를 예측하고자 할 때 입력 시퀀스 행렬로부터<br> 미래 시점의 단어까지도 참고할 수 있는 현상이 발생하여 이를 방지하기 위하여 **마스킹**을 사용한다"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <img src=\"https://production-media.paperswithcode.com/methods/multi-head-attention_l1A3G7a.png\" width=\"300\" height=\"300\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Add&Norm 계층**<br>\n",
    "각 인스턴스에서 입력단어 임베딩 벡터를 멀티-헤드 어텐션 계층의 출력 벡터에 바로 더함으로써 잔차 연결이 설정된다.<br>\n",
    "이렇게 하면 네트워크 전체에서 경사를 전달하기 더 쉽고, 경사가 폭발하거나 소실하는 문제를 피할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <img src=\"https://wikidocs.net/images/page/31379/transformer22.PNG\" width=\"200\" height=\"200\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feed Forward 계층**<br>\n",
    "인코더와 디코더 유닛 모두에서 시퀀스의 모든 단어에 대해 정규화된 잔차 출력 벡터가 공통 feed forward 계층을 통해 전달된다.<br>\n",
    "단어 전체에 공통 매개변수 세트가 있기 때문에 이 계층은 시퀀스 전체에서 더 광범위한 패턴을 학습하는 데 도움이 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**선형 및 소프트맥스 계층**<br>\n",
    "선형 계층은 벡터 시퀀스를 단어 사전의 길이와 똑같은 크기를 갖는 벡터로 변환한다.<br>\n",
    "소프트맥스 계층은 이 출력을 확률 벡터로 변환한다. \n",
    "<br> >> 이 확률은 사전에서 각 단어가 시퀀스의 다음 단어로 등장할 확률을 의미한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-07T06:07:39.846104Z",
     "start_time": "2023-02-07T06:07:39.832105Z"
    }
   },
   "outputs": [],
   "source": [
    "class PosEnc(nn.Module):\n",
    "    def __init__(self, d_m, dropout=0.2, size_limit=5000):\n",
    "\n",
    "        # d_m은 임베딩 차원과 동일\n",
    "        super(PosEnc, self).__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        p_enc = torch.zeros(size_limit, d_m)\n",
    "        pos = torch.arange(0, size_limit, dtype=torch.float).unsqueeze(1)\n",
    "        \n",
    "        # divider는 라디안 리스트로 여기에 단어 위치 인덱스를 곱하여\n",
    "        # sin,cos 함수에 제공한다\n",
    "        divider = torch.exp(torch.arange(0, d_m, 2).float() * (-math.log(10000.0) / d_m))\n",
    "        p_enc[:, 0::2] = torch.sin(pos * divider)\n",
    "        p_enc[:, 1::2] = torch.cos(pos * divider)\n",
    "        p_enc = p_enc.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('p_enc', p_enc)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.dropout(x + self.p_enc[:x.size(0), :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 트랜스포머 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-07T06:07:39.831104Z",
     "start_time": "2023-02-07T06:07:39.817104Z"
    }
   },
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, num_token, num_inputs, num_heads, num_hidden, num_layers, dropout=0.3):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.model_name = 'transformer'\n",
    "        self.mask_source = None\n",
    "        self.position_enc = PosEnc(num_inputs, dropout) # 위치 인코딩\n",
    "        layers_enc = TransformerEncoderLayer(num_inputs, num_heads, num_hidden, dropout) # TransformerEncoderLayer\n",
    "        self.enc_transformer = TransformerEncoder(layers_enc, num_layers) # TransformerEncoder\n",
    "        self.enc = nn.Embedding(num_token, num_inputs)\n",
    "        self.num_inputs = num_inputs\n",
    "        self.dec = nn.Linear(num_inputs, num_token)\n",
    "        self.init_params()\n",
    "\n",
    "    def _gen_sqr_nxt_mask(self, size):\n",
    "        msk = (torch.triu(torch.ones(size, size)) == 1).transpose(0, 1)\n",
    "        msk = msk.float().masked_fill(msk == 0, float('-inf'))\n",
    "        msk = msk.masked_fill(msk == 1, float(0.0))\n",
    "        return msk\n",
    "\n",
    "    def init_params(self):\n",
    "        initial_rng = 0.12\n",
    "        self.enc.weight.data.uniform_(-initial_rng, initial_rng)\n",
    "        self.dec.bias.data.zero_()\n",
    "        self.dec.weight.data.uniform_(-initial_rng, initial_rng)\n",
    "    \n",
    "    # forward 메서드에서 입력은 위치적으로 인코딩된 다음 인코더를 통과한 후 디코더를 통과한다\n",
    "    def forward(self, source):\n",
    "        if self.mask_source is None or self.mask_source.size(0) != len(source):\n",
    "            dvc = source.device\n",
    "            msk = self._gen_sqr_nxt_mask(len(source)).to(dvc)\n",
    "            self.mask_source = msk\n",
    "\n",
    "        source = self.enc(source) * math.sqrt(self.num_inputs)\n",
    "        source = self.position_enc(source)\n",
    "        op = self.enc_transformer(source, self.mask_source)\n",
    "        op = self.dec(op)\n",
    "        return op"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sin,cos 함수는 순차 패턴을 제공하기 위해 번갈아 사용된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터셋 로딩 및 처리\n",
    "위키피디아 텍스트 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-07T06:07:45.264113Z",
     "start_time": "2023-02-07T06:07:39.847104Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading wikitext-2-v1.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".data\\wikitext-2\\wikitext-2-v1.zip: 100%|█████████████████████████████████████████| 4.48M/4.48M [00:02<00:00, 1.99MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting\n"
     ]
    }
   ],
   "source": [
    "# 데이터셋을 다운로드하고, 사전을 토큰화하고 데이터셋을 훈련,검증,테스트셋으로 분할\n",
    "TEXT = torchtext.data.Field(tokenize=get_tokenizer(\"basic_english\"), lower=True, eos_token='<eos>', init_token='<sos>')\n",
    "training_text, validation_text, testing_text = torchtext.datasets.WikiText2.splits(TEXT)\n",
    "TEXT.build_vocab(training_text)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "# 훈련과 검증에 사용할 배치 크기를 정의하고 다음과 같이 배치 생성 함수를 선언\n",
    "def gen_batches(text_dataset, batch_size):\n",
    "    text_dataset = TEXT.numericalize([text_dataset.examples[0].text])\n",
    "    # 텍스트 데이터셋을 batch_size와 동일한 크기의 부분으로 나눔\n",
    "    num_batches = text_dataset.size(0) // batch_size\n",
    "    \n",
    "    # 배치 밖에 위치한 데이터 포인트(나머지에 해당하는 부분)를 제거\n",
    "    text_dataset = text_dataset.narrow(0, 0, num_batches * batch_size)\n",
    "    \n",
    "    # 데이터셋을 배치에 균등하게 배포\n",
    "    text_dataset = text_dataset.view(batch_size, -1).t().contiguous()\n",
    "    \n",
    "    return text_dataset.to(device)\n",
    "\n",
    "training_batch_size = 32\n",
    "evaluation_batch_size = 16\n",
    "\n",
    "training_data = gen_batches(training_text, training_batch_size)\n",
    "validation_data = gen_batches(validation_text, evaluation_batch_size)\n",
    "testing_data = gen_batches(testing_text, evaluation_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-07T06:07:45.279113Z",
     "start_time": "2023-02-07T06:07:45.265113Z"
    }
   },
   "outputs": [],
   "source": [
    "# 최대 시퀀스 길이를 정의 \n",
    "max_seq_len = 64\n",
    "\n",
    "# 그에 따라 입력 시퀀스와 각 배치에 대한 출력 타깃을 생성하는 함수를 생성\n",
    "def return_batch(src, k):\n",
    "    sequence_length = min(max_seq_len, len(src) - 1 - k)\n",
    "    sequence_data = src[k:k+sequence_length]\n",
    "    sequence_label = src[k+1:k+1+sequence_length].view(-1)\n",
    "    return sequence_data, sequence_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 트랜스포머 모델 훈련\n",
    "모델 매개변수 정의 및 인스턴스화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-07T06:07:45.430113Z",
     "start_time": "2023-02-07T06:07:45.280113Z"
    }
   },
   "outputs": [],
   "source": [
    "num_tokens = len(TEXT.vocab.stoi) # 사전 크기\n",
    "embedding_size = 256 # 임베딩 계층의 차원\n",
    "num_hidden_params = 256 # 트랜스포머 인코더의 은닉 계층 차원\n",
    "num_layers = 2 # 트랜스포머 인코더 내부의 트랜스포머 인코더 계층 개수\n",
    "num_heads = 2 # 어텐션 모델의 헤드 개수(멀티-헤드)\n",
    "dropout = 0.25 \n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "lrate = 4.0 # 학습률\n",
    "transformer_model = Transformer(num_tokens, embedding_size, num_heads, num_hidden_params, num_layers, dropout).to(device)\n",
    "optim_module = torch.optim.SGD(transformer_model.parameters(), lr=lrate)\n",
    "sched_module = torch.optim.lr_scheduler.StepLR(optim_module, 1.0, gamma=0.88)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-07T06:07:45.445113Z",
     "start_time": "2023-02-07T06:07:45.431114Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_model():\n",
    "    transformer_model.train()\n",
    "    loss_total = 0.\n",
    "    time_start = time.time()\n",
    "    num_tokens = len(TEXT.vocab.stoi)\n",
    "    for b, i in enumerate(range(0, training_data.size(0) - 1, max_seq_len)):\n",
    "        train_data_batch, train_label_batch = return_batch(training_data, i)\n",
    "        optim_module.zero_grad()\n",
    "        op = transformer_model(train_data_batch)\n",
    "        loss_curr = loss_func(op.view(-1, num_tokens), train_label_batch)\n",
    "        loss_curr.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(transformer_model.parameters(), 0.6)\n",
    "        optim_module.step()\n",
    "\n",
    "        loss_total += loss_curr.item()\n",
    "        interval = 100\n",
    "        if b % interval == 0 and b > 0:\n",
    "            loss_interval = loss_total / interval\n",
    "            time_delta = time.time() - time_start\n",
    "            print(f\"epoch {ep}, {b}/{len(training_data)//max_seq_len} batches, training loss {loss_interval:.2f},\n",
    "                  training perplexity {math.exp(loss_interval):.2f}\")\n",
    "            loss_total = 0\n",
    "            time_start = time.time()\n",
    "\n",
    "def eval_model(eval_model_obj, eval_data_source):\n",
    "    eval_model_obj.eval() \n",
    "    loss_total = 0.\n",
    "    num_tokens = len(TEXT.vocab.stoi)\n",
    "    with torch.no_grad():\n",
    "        for j in range(0, eval_data_source.size(0) - 1, max_seq_len):\n",
    "            eval_data, eval_label = return_batch(eval_data_source, j)\n",
    "            op = eval_model_obj(eval_data)\n",
    "            op_flat = op.view(-1, num_tokens)\n",
    "            loss_total += len(eval_data) * loss_func(op_flat, eval_label).item()\n",
    "    return loss_total / (len(eval_data_source) - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-07T06:10:16.630809Z",
     "start_time": "2023-02-07T06:07:45.446113Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, 100/1018 batches, training loss 8.63, training perplexity 5623.58\n",
      "epoch 1, 200/1018 batches, training loss 7.19, training perplexity 1324.49\n",
      "epoch 1, 300/1018 batches, training loss 6.79, training perplexity 887.43\n",
      "epoch 1, 400/1018 batches, training loss 6.56, training perplexity 703.80\n",
      "epoch 1, 500/1018 batches, training loss 6.46, training perplexity 637.17\n",
      "epoch 1, 600/1018 batches, training loss 6.32, training perplexity 556.63\n",
      "epoch 1, 700/1018 batches, training loss 6.25, training perplexity 515.82\n",
      "epoch 1, 800/1018 batches, training loss 6.13, training perplexity 458.09\n",
      "epoch 1, 900/1018 batches, training loss 6.10, training perplexity 444.86\n",
      "epoch 1, 1000/1018 batches, training loss 6.07, training perplexity 430.96\n",
      "\n",
      "epoch 1, validation loss 5.87, validation perplexity 355.73\n",
      "\n",
      "epoch 2, 100/1018 batches, training loss 5.98, training perplexity 396.37\n",
      "epoch 2, 200/1018 batches, training loss 5.90, training perplexity 366.02\n",
      "epoch 2, 300/1018 batches, training loss 5.82, training perplexity 338.08\n",
      "epoch 2, 400/1018 batches, training loss 5.79, training perplexity 327.90\n",
      "epoch 2, 500/1018 batches, training loss 5.81, training perplexity 334.20\n",
      "epoch 2, 600/1018 batches, training loss 5.77, training perplexity 319.93\n",
      "epoch 2, 700/1018 batches, training loss 5.77, training perplexity 321.89\n",
      "epoch 2, 800/1018 batches, training loss 5.65, training perplexity 284.20\n",
      "epoch 2, 900/1018 batches, training loss 5.68, training perplexity 292.86\n",
      "epoch 2, 1000/1018 batches, training loss 5.70, training perplexity 299.85\n",
      "\n",
      "epoch 2, validation loss 5.63, validation perplexity 277.55\n",
      "\n",
      "epoch 3, 100/1018 batches, training loss 5.67, training perplexity 289.14\n",
      "epoch 3, 200/1018 batches, training loss 5.60, training perplexity 270.80\n",
      "epoch 3, 300/1018 batches, training loss 5.56, training perplexity 258.57\n",
      "epoch 3, 400/1018 batches, training loss 5.52, training perplexity 250.06\n",
      "epoch 3, 500/1018 batches, training loss 5.54, training perplexity 255.45\n",
      "epoch 3, 600/1018 batches, training loss 5.52, training perplexity 249.70\n",
      "epoch 3, 700/1018 batches, training loss 5.54, training perplexity 253.59\n",
      "epoch 3, 800/1018 batches, training loss 5.39, training perplexity 219.78\n",
      "epoch 3, 900/1018 batches, training loss 5.44, training perplexity 230.06\n",
      "epoch 3, 1000/1018 batches, training loss 5.49, training perplexity 241.54\n",
      "\n",
      "epoch 3, validation loss 5.38, validation perplexity 217.79\n",
      "\n",
      "epoch 4, 100/1018 batches, training loss 5.47, training perplexity 236.82\n",
      "epoch 4, 200/1018 batches, training loss 5.40, training perplexity 221.19\n",
      "epoch 4, 300/1018 batches, training loss 5.36, training perplexity 213.75\n",
      "epoch 4, 400/1018 batches, training loss 5.34, training perplexity 209.09\n",
      "epoch 4, 500/1018 batches, training loss 5.36, training perplexity 212.88\n",
      "epoch 4, 600/1018 batches, training loss 5.34, training perplexity 209.25\n",
      "epoch 4, 700/1018 batches, training loss 5.36, training perplexity 213.25\n",
      "epoch 4, 800/1018 batches, training loss 5.21, training perplexity 183.56\n",
      "epoch 4, 900/1018 batches, training loss 5.27, training perplexity 193.69\n",
      "epoch 4, 1000/1018 batches, training loss 5.32, training perplexity 204.57\n",
      "\n",
      "epoch 4, validation loss 5.30, validation perplexity 200.97\n",
      "\n",
      "epoch 5, 100/1018 batches, training loss 5.31, training perplexity 202.11\n",
      "epoch 5, 200/1018 batches, training loss 5.25, training perplexity 189.78\n",
      "epoch 5, 300/1018 batches, training loss 5.22, training perplexity 185.52\n",
      "epoch 5, 400/1018 batches, training loss 5.20, training perplexity 181.03\n",
      "epoch 5, 500/1018 batches, training loss 5.22, training perplexity 184.63\n",
      "epoch 5, 600/1018 batches, training loss 5.21, training perplexity 182.49\n",
      "epoch 5, 700/1018 batches, training loss 5.23, training perplexity 186.74\n",
      "epoch 5, 800/1018 batches, training loss 5.07, training perplexity 158.73\n",
      "epoch 5, 900/1018 batches, training loss 5.13, training perplexity 168.68\n",
      "epoch 5, 1000/1018 batches, training loss 5.18, training perplexity 178.15\n",
      "\n",
      "epoch 5, validation loss 5.24, validation perplexity 188.02\n",
      "\n"
     ]
    }
   ],
   "source": [
    "min_validation_loss = float(\"inf\")\n",
    "eps = 5\n",
    "best_model_so_far = None\n",
    "\n",
    "for ep in range(1, eps + 1):\n",
    "    ep_time_start = time.time()\n",
    "    train_model()\n",
    "    validation_loss = eval_model(transformer_model, validation_data)\n",
    "    print()\n",
    "    print(f\"epoch {ep:}, validation loss {validation_loss:.2f}, validation perplexity {math.exp(validation_loss):.2f}\")\n",
    "    print()\n",
    "\n",
    "    if validation_loss < min_validation_loss:\n",
    "        min_validation_loss = validation_loss\n",
    "        best_model_so_far = transformer_model\n",
    "\n",
    "    sched_module.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**perplexity(혼란도)**는 자연어 처리에서 **확률분포(여기서는 언어 모델)**가 샘플에 얼마나 잘 맞는지를 나타내기 위해 사용되는 지표이다.<br>\n",
    "-> 작을수록 좋음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델 훈련이후 테스트셋에서 모델 성능평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-07T06:10:18.029603Z",
     "start_time": "2023-02-07T06:10:16.631810Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing loss 5.15, testing perplexity 172.64\n"
     ]
    }
   ],
   "source": [
    "testing_loss = eval_model(best_model_so_far, testing_data)\n",
    "print(f\"testing loss {testing_loss:.2f}, testing perplexity {math.exp(testing_loss):.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
